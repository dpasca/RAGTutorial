# Provider configuration
USE_OLLAMA=true                          # Set to 'false' to use OpenAI
OLLAMA_BASE_URL=http://localhost:11434   # Base URL for Ollama API

# Model configuration
MODEL_NAME=llama3                        # For Ollama: llama3, mistral, etc. For OpenAI: gpt-4o-mini, gpt-3.5-turbo
EMBEDDING_MODEL_NAME=all-minilm:l6-v2    # For embedding when using Ollama (not used for OpenAI)

# OpenAI configuration (only needed if USE_OLLAMA=false)
OPENAI_API_KEY=your_openai_api_key_here  # Get your key at https://platform.openai.com/api-keys
