# Provider configuration
USE_OLLAMA=true                          # Set to 'false' to use OpenAI
OLLAMA_BASE_URL=http://localhost:11434   # Base URL for Ollama API

# Model configuration
MODEL_NAME=qwen2.5:3b                        # For Ollama: llama3, mistral, etc. For OpenAI: gpt-4o-mini, gpt-3.5-turbo
EMBEDDING_MODEL_NAME=nomic-embed-text    # For embedding when using Ollama (not used for OpenAI)

# OpenAI configuration (not needed when using Ollama)
# OPENAI_API_KEY=your_openai_api_key_here
