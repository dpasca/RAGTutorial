# Provider configuration
USE_OLLAMA=true                          # Set to 'false' to use OpenAI
OLLAMA_BASE_URL=http://localhost:11434   # Base URL for Ollama API

# Model configuration
MODEL_NAME=qwen2.5:3b                        # For Ollama: llama3, mistral, etc. For OpenAI: gpt-4o-mini, gpt-3.5-turbo

# OpenAI configuration (only needed if USE_OLLAMA=false)
OPENAI_API_KEY=your_openai_api_key_here  # Get your key at https://platform.openai.com/api-keys
